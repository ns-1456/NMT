{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Colab: T5-Nano (Python → C++) End-to-End Pipeline\n",
        "\n",
        "This notebook is **Google Colab friendly**. It starts by cloning your GitHub repo, then runs:\n",
        "\n",
        "- Data prep (XLCoST)\n",
        "- Tokenizer training\n",
        "- T5-Nano init (random weights)\n",
        "- Training\n",
        "- Inference demo\n",
        "\n",
        "Tip: In Colab, enable a GPU: **Runtime → Change runtime type → GPU**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ed2fbb4c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/NMT\n",
            "## \u001b[32mmain\u001b[m...\u001b[31morigin/main\u001b[m\n",
            "\u001b[31m??\u001b[m NMT/\n"
          ]
        }
      ],
      "source": [
        "# --- Clone repo (idempotent) ---\n",
        "# Always anchor at /content so we don't accidentally clone into /content/NMT/NMT\n",
        "%cd /content\n",
        "\n",
        "REPO_URL = \"https://github.com/ns-1456/NMT.git\"\n",
        "REPO_DIR = \"NMT\"\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.isdir(REPO_DIR):\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "\n",
        "%cd /content/{REPO_DIR}\n",
        "!git status -sb || true\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e4bcefe8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (avoid reinstalling torch in Colab)\n",
        "!pip -q install -U pip\n",
        "!pip -q install transformers datasets tokenizers pandas scikit-learn accelerate gdown tqdm matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "16461f59",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "repo: /content/NMT\n",
            "quick_run: True\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "REPO_ROOT = Path.cwd()\n",
        "DATA_PROCESSED = REPO_ROOT / \"data\" / \"processed\"\n",
        "TOKENIZER_DIR = REPO_ROOT / \"custom_tokenizer\"\n",
        "CHECKPOINT_DIR = REPO_ROOT / \"t5_nano_checkpoints\"\n",
        "FINAL_MODEL_DIR = REPO_ROOT / \"final_model\"\n",
        "\n",
        "QUICK_RUN = True\n",
        "MAX_SAMPLES = 2000 if QUICK_RUN else None\n",
        "EPOCHS = 1 if QUICK_RUN else 30\n",
        "BATCH_SIZE = 8 if QUICK_RUN else 32\n",
        "\n",
        "print(\"repo:\", REPO_ROOT)\n",
        "print(\"quick_run:\", QUICK_RUN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc28e93d",
      "metadata": {},
      "source": [
        "## 1) Data prep (XLCoST → `data/processed/`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7726d1f7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `PY')\n",
            "zip exists: True size: 297821023\n",
            "total entries: 1938\n",
            "\n",
            "first 50 entries:\n",
            "XLCoST_data/\n",
            "__MACOSX/._XLCoST_data\n",
            "XLCoST_data/retrieval/\n",
            "__MACOSX/XLCoST_data/._retrieval\n",
            "XLCoST_data/generation/\n",
            "__MACOSX/XLCoST_data/._generation\n",
            "XLCoST_data/retrieval/nl2code_search/\n",
            "__MACOSX/XLCoST_data/retrieval/._nl2code_search\n",
            "XLCoST_data/retrieval/code2code_search/\n",
            "__MACOSX/XLCoST_data/retrieval/._code2code_search\n",
            "XLCoST_data/retrieval/.ipynb_checkpoints/\n",
            "__MACOSX/XLCoST_data/retrieval/._.ipynb_checkpoints\n",
            "XLCoST_data/generation/pair_data_tok_full_desc_comment/\n",
            "__MACOSX/XLCoST_data/generation/._pair_data_tok_full_desc_comment\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/\n",
            "__MACOSX/XLCoST_data/generation/._pair_data_tok_1_comment\n",
            "XLCoST_data/generation/pair_data_tok_full_desc/\n",
            "__MACOSX/XLCoST_data/generation/._pair_data_tok_full_desc\n",
            "XLCoST_data/generation/pair_data_tok_full/\n",
            "__MACOSX/XLCoST_data/generation/._pair_data_tok_full\n",
            "XLCoST_data/generation/pair_data_tok_1/\n",
            "__MACOSX/XLCoST_data/generation/._pair_data_tok_1\n",
            "XLCoST_data/retrieval/nl2code_search/program_level/\n",
            "__MACOSX/XLCoST_data/retrieval/nl2code_search/._program_level\n",
            "XLCoST_data/retrieval/nl2code_search/snippet_level/\n",
            "__MACOSX/XLCoST_data/retrieval/nl2code_search/._snippet_level\n",
            "XLCoST_data/retrieval/code2code_search/program_level/\n",
            "__MACOSX/XLCoST_data/retrieval/code2code_search/._program_level\n",
            "XLCoST_data/retrieval/code2code_search/snippet_level/\n",
            "__MACOSX/XLCoST_data/retrieval/code2code_search/._snippet_level\n",
            "XLCoST_data/retrieval/.ipynb_checkpoints/code2codesearch_data-checkpoint.ipynb\n",
            "__MACOSX/XLCoST_data/retrieval/.ipynb_checkpoints/._code2codesearch_data-checkpoint.ipynb\n",
            "XLCoST_data/retrieval/.ipynb_checkpoints/create_data-checkpoint.ipynb\n",
            "__MACOSX/XLCoST_data/retrieval/.ipynb_checkpoints/._create_data-checkpoint.ipynb\n",
            "XLCoST_data/generation/pair_data_tok_full_desc_comment/C#-desc/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_full_desc_comment/._C#-desc\n",
            "XLCoST_data/generation/pair_data_tok_full_desc_comment/Javascript-desc/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_full_desc_comment/._Javascript-desc\n",
            "XLCoST_data/generation/pair_data_tok_full_desc_comment/PHP-desc/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_full_desc_comment/._PHP-desc\n",
            "XLCoST_data/generation/pair_data_tok_full_desc_comment/Python-desc/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_full_desc_comment/._Python-desc\n",
            "XLCoST_data/generation/pair_data_tok_full_desc_comment/C-desc/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_full_desc_comment/._C-desc\n",
            "XLCoST_data/generation/pair_data_tok_full_desc_comment/C++-desc/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_full_desc_comment/._C++-desc\n",
            "XLCoST_data/generation/pair_data_tok_full_desc_comment/Java-desc/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_full_desc_comment/._Java-desc\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/Javascript-comment/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1_comment/._Javascript-comment\n",
            "\n",
            "entries containing pair_data_tok_1: 732\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/\n",
            "__MACOSX/XLCoST_data/generation/._pair_data_tok_1_comment\n",
            "XLCoST_data/generation/pair_data_tok_1/\n",
            "__MACOSX/XLCoST_data/generation/._pair_data_tok_1\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/Javascript-comment/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1_comment/._Javascript-comment\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/C-comment/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1_comment/._C-comment\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/C++-comment/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1_comment/._C++-comment\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/Java-comment/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1_comment/._Java-comment\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/C#-comment/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1_comment/._C#-comment\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/PHP-comment/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1_comment/._PHP-comment\n",
            "XLCoST_data/generation/pair_data_tok_1_comment/Python-comment/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1_comment/._Python-comment\n",
            "XLCoST_data/generation/pair_data_tok_1/C++-Javascript/\n",
            "__MACOSX/XLCoST_data/generation/pair_data_tok_1/._C++-Javascript\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'PY' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3730004979.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mPY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'PY' is not defined"
          ]
        }
      ],
      "source": [
        "!python - <<'PY'\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "zip_path = Path(\"data/raw/XLCoST_data.zip\")\n",
        "print(\"zip exists:\", zip_path.exists(), \"size:\", zip_path.stat().st_size if zip_path.exists() else None)\n",
        "\n",
        "with zipfile.ZipFile(zip_path) as z:\n",
        "    names = z.namelist()\n",
        "    print(\"total entries:\", len(names))\n",
        "\n",
        "    print(\"\\nfirst 50 entries:\")\n",
        "    for n in names[:50]:\n",
        "        print(n)\n",
        "\n",
        "    hits = [n for n in names if \"pair_data_tok_1\" in n]\n",
        "    print(\"\\nentries containing pair_data_tok_1:\", len(hits))\n",
        "    for n in hits[:20]:\n",
        "        print(n)\n",
        "PY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e41015a9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running: python -u data_prep.py --max_samples 2000\n",
            "\n",
            "--- data_prep.py stdout ---\n",
            "\n",
            "[data_prep] Downloading XLCoST zip to data/raw/XLCoST_data.zip\n",
            "[data_prep] Extracting data/raw/XLCoST_data.zip into data/raw\n",
            "\n",
            "\n",
            "--- data_prep.py stderr ---\n",
            "\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Cp3vFITRaUEJwPoeI_uv0cC6KVyvDc4F\n",
            "From (redirected): https://drive.google.com/uc?id=1Cp3vFITRaUEJwPoeI_uv0cC6KVyvDc4F&confirm=t&uuid=0dcf5a2c-22b7-4b76-8160-4650807533e2\n",
            "To: /content/NMT/data/raw/XLCoST_data.zip\n",
            "\n",
            "  0%|          | 0.00/298M [00:00<?, ?B/s]\n",
            "  6%|▌         | 16.8M/298M [00:00<00:01, 162MB/s]\n",
            " 12%|█▏        | 35.1M/298M [00:00<00:01, 170MB/s]\n",
            " 19%|█▉        | 57.1M/298M [00:00<00:01, 191MB/s]\n",
            " 26%|██▋       | 78.6M/298M [00:00<00:01, 200MB/s]\n",
            " 33%|███▎      | 99.1M/298M [00:00<00:00, 199MB/s]\n",
            " 40%|████      | 120M/298M [00:00<00:00, 199MB/s] \n",
            " 47%|████▋     | 141M/298M [00:00<00:00, 196MB/s]\n",
            " 54%|█████▍    | 160M/298M [00:01<00:01, 112MB/s]\n",
            " 59%|█████▉    | 176M/298M [00:01<00:01, 120MB/s]\n",
            " 65%|██████▍   | 192M/298M [00:01<00:00, 128MB/s]\n",
            " 71%|███████   | 211M/298M [00:01<00:00, 141MB/s]\n",
            " 77%|███████▋  | 230M/298M [00:01<00:00, 153MB/s]\n",
            " 83%|████████▎ | 247M/298M [00:01<00:00, 158MB/s]\n",
            " 89%|████████▊ | 264M/298M [00:01<00:00, 150MB/s]\n",
            " 94%|█████████▍| 280M/298M [00:01<00:00, 143MB/s]\n",
            "100%|██████████| 298M/298M [00:01<00:00, 154MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/NMT/data_prep.py\", line 423, in <module>\n",
            "    raise SystemExit(main())\n",
            "                     ^^^^^^\n",
            "  File \"/content/NMT/data_prep.py\", line 317, in main\n",
            "    base = _pair_dir(xlcost_root, level=args.level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/NMT/data_prep.py\", line 162, in _pair_dir\n",
            "    raise FileNotFoundError(f\"Missing expected directory: {base}\")\n",
            "FileNotFoundError: Missing expected directory: data/raw/XLCoST_data/pair_data_tok_1\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "data_prep.py failed with exit code 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3557482983.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- data_prep.py stderr ---\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data_prep.py failed with exit code {proc.returncode}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nProduced:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: data_prep.py failed with exit code 1"
          ]
        }
      ],
      "source": [
        "# Clean any stale XLCoST artifacts (zip + extracted folders)\n",
        "subprocess.run([\"rm\", \"-rf\", \"data/raw/XLCoST_data\"], check=False)\n",
        "subprocess.run([\"rm\", \"-rf\", \"data/raw/__MACOSX\"], check=False)\n",
        "subprocess.run([\"rm\", \"-f\",  \"data/raw/XLCoST_data.zip\"], check=False)\n",
        "\n",
        "cmd = [\"python\", \"-u\", \"data_prep.py\"]\n",
        "if MAX_SAMPLES is not None:\n",
        "    cmd += [\"--max_samples\", str(MAX_SAMPLES)]\n",
        "\n",
        "print(\"Running:\", \" \".join(cmd))\n",
        "proc = subprocess.run(cmd, text=True, capture_output=True)\n",
        "\n",
        "print(\"\\n--- data_prep.py stdout ---\\n\")\n",
        "print(proc.stdout)\n",
        "\n",
        "if proc.returncode != 0:\n",
        "    print(\"\\n--- data_prep.py stderr ---\\n\")\n",
        "    print(proc.stderr)\n",
        "    raise RuntimeError(f\"data_prep.py failed with exit code {proc.returncode}\")\n",
        "\n",
        "print(\"\\nProduced:\")\n",
        "for p in sorted(DATA_PROCESSED.glob(\"*\")):\n",
        "    print(\"-\", p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic dataset inspection + visualization (Arrow dataset preferred; JSONL fallback)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "arrow_dir = DATA_PROCESSED / \"xlcost_py_cpp_snippet\"\n",
        "if arrow_dir.exists():\n",
        "    from datasets import load_from_disk\n",
        "\n",
        "    ds = load_from_disk(str(arrow_dir))\n",
        "    train_df = pd.DataFrame(ds[\"train\"])\n",
        "else:\n",
        "    train_df = pd.read_json(DATA_PROCESSED / \"train.jsonl\", lines=True)\n",
        "\n",
        "print(\"train rows:\", len(train_df))\n",
        "\n",
        "train_df[\"source_len\"] = train_df[\"source\"].astype(str).map(len)\n",
        "train_df[\"target_len\"] = train_df[\"target\"].astype(str).map(len)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
        "ax[0].hist(train_df[\"source_len\"], bins=50)\n",
        "ax[0].set_title(\"Train source char length\")\n",
        "ax[1].hist(train_df[\"target_len\"], bins=50)\n",
        "ax[1].set_title(\"Train target char length\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "train_df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Train tokenizer (Byte-Level BPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "subprocess.run([\"python\", \"train_tokenizer.py\"], check=True)\n",
        "print(\"Tokenizer dir:\", TOKENIZER_DIR)\n",
        "!ls -la custom_tokenizer | head\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Verify model config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import model_config\n",
        "\n",
        "tok = model_config.load_tokenizer()\n",
        "model = model_config.build_t5_nano(tok)\n",
        "params = model_config.count_parameters(model)\n",
        "print(f\"T5-Nano parameter count: {params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\n",
        "        \"CUDA GPU not available. In Colab: Runtime → Change runtime type → GPU. \"\n",
        "        \"(train.py uses fp16=True by default.)\"\n",
        "    )\n",
        "\n",
        "cmd = [\n",
        "    \"python\",\n",
        "    \"train.py\",\n",
        "    \"--per_device_batch_size\",\n",
        "    str(BATCH_SIZE),\n",
        "    \"--num_train_epochs\",\n",
        "    str(EPOCHS),\n",
        "]\n",
        "print(\"Running:\", \" \".join(cmd))\n",
        "subprocess.run(cmd, check=True)\n",
        "print(\"Final model dir exists:\", FINAL_MODEL_DIR.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves (train/eval loss)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trainer_states = list(CHECKPOINT_DIR.glob(\"checkpoint-*/trainer_state.json\"))\n",
        "if not trainer_states:\n",
        "    root_state = CHECKPOINT_DIR / \"trainer_state.json\"\n",
        "    trainer_states = [root_state] if root_state.exists() else []\n",
        "\n",
        "if not trainer_states:\n",
        "    print(\"No trainer_state.json found yet\")\n",
        "else:\n",
        "    state_path = max(trainer_states, key=lambda p: p.stat().st_mtime)\n",
        "    state = json.loads(state_path.read_text())\n",
        "    logs = state.get(\"log_history\", [])\n",
        "\n",
        "    steps, train_losses = [], []\n",
        "    eval_steps, eval_losses = [], []\n",
        "    for item in logs:\n",
        "        if \"loss\" in item and \"eval_loss\" not in item:\n",
        "            steps.append(item.get(\"step\"))\n",
        "            train_losses.append(item[\"loss\"])\n",
        "        if \"eval_loss\" in item:\n",
        "            eval_steps.append(item.get(\"step\"))\n",
        "            eval_losses.append(item[\"eval_loss\"])\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    if train_losses:\n",
        "        plt.plot(steps, train_losses, label=\"train_loss\")\n",
        "    if eval_losses:\n",
        "        plt.plot(eval_steps, eval_losses, label=\"eval_loss\")\n",
        "    plt.title(\"Training curves\")\n",
        "    plt.xlabel(\"step\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.2)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Inference demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import inference\n",
        "\n",
        "sample_python = \"\"\"\\\n",
        "def sum_upto(n):\n",
        "    s = 0\n",
        "    for i in range(n + 1):\n",
        "        s += i\n",
        "    return s\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== Python ===\")\n",
        "print(sample_python)\n",
        "print(\"=== C++ (generated) ===\")\n",
        "inference.translate(sample_python)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
